{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e85160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "json_path = '../dataset/dev.json'  \n",
    "output_path = '../dataset/dev_eng_trans.json'\n",
    "\n",
    "# JSON íŒŒì¼ ì½ê¸°\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)  # ë¦¬ìŠ¤íŠ¸[ë”•ì…”ë„ˆë¦¬] í˜•íƒœ ìœ ì§€ë¨\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed4bcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "#os.environ['OPENAI_API_KEY'] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a20fac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    request_timeout=60,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a Korean-to-English translation assistant.\n",
    "You will receive a short conversation transcript written in Korean, consisting of three utterances.\n",
    "Your task is to translate **only the last utterance** into natural English.\n",
    "Respond with the translated sentence only â€” no extra text, comments, or formatting.\n",
    "\"\"\"\n",
    "\n",
    "integrated_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt.strip()),\n",
    "    (\"human\", \"\"\"\n",
    "<Transcript>\n",
    "{transcript}\n",
    "\n",
    "<Translate the last utterance>\n",
    "\"\"\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a3c564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating utterances: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3084/3084 [51:10<00:00,  1.00it/s]  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m progress.close()\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# ê²°ê³¼ ì €ì¥\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43moutput_path\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     51\u001b[39m     json.dump(translated_dataset, f, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m2\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… ì €ì¥ ì™„ë£Œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'output_path' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# ğŸ”¢ ì´ ë²ˆì—­ ë¬¸ì¥ ìˆ˜ ê³„ì‚°\n",
    "total_utterances = sum(len(sample[\"input\"][\"conversation\"]) for sample in dataset)\n",
    "\n",
    "# ğŸ” ë²ˆì—­ ì²˜ë¦¬\n",
    "translated_dataset = []\n",
    "progress = tqdm(total=total_utterances, desc=\"Translating utterances\")\n",
    "\n",
    "for sample in dataset:\n",
    "    new_sample = sample.copy()\n",
    "    new_sample[\"input\"] = sample[\"input\"].copy()\n",
    "    new_sample[\"input\"][\"conversation\"] = []\n",
    "\n",
    "    conversation = sample[\"input\"][\"conversation\"]\n",
    "\n",
    "    for i in range(len(conversation)):\n",
    "        start_idx = max(0, i - 2)\n",
    "        context_slice = conversation[start_idx:i+1]\n",
    "\n",
    "        if len(context_slice) == 0:\n",
    "            continue\n",
    "\n",
    "        # transcript ë§Œë“¤ê¸°\n",
    "        transcript_lines = [\n",
    "            f\"speaker{utt['speaker']}: {utt['utterance']}\" for utt in context_slice\n",
    "        ]\n",
    "        transcript = \"\\n\".join(transcript_lines)\n",
    "\n",
    "        # GPT í˜¸ì¶œ\n",
    "        try:\n",
    "            chain = integrated_prompt | llm\n",
    "            response = chain.invoke({\"transcript\": transcript})\n",
    "            translated = response.content.strip()\n",
    "        except Exception as e:\n",
    "            translated = f\"[Error] {str(e)}\"\n",
    "\n",
    "        # ì› ë°œí™” ë³µì‚¬ í›„ ë²ˆì—­ ì¶”ê°€\n",
    "        new_utt = conversation[i].copy()\n",
    "        new_utt[\"translated_utterance\"] = translated\n",
    "        new_sample[\"input\"][\"conversation\"].append(new_utt)\n",
    "\n",
    "        # âœ… tqdm í•œ ì¹¸ ì¦ê°€\n",
    "        progress.update(1)\n",
    "\n",
    "    translated_dataset.append(new_sample)\n",
    "\n",
    "progress.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62cd0d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: ../dataset/dev_english.json\n"
     ]
    }
   ],
   "source": [
    "output_path = '../dataset/dev_english.json'\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(translated_dataset, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
